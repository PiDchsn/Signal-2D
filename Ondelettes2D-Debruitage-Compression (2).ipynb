{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformée en Ondelettes 2D, application au traitement des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as scp\n",
    "import pylab as pyl\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import holoviews as hv\n",
    "import param\n",
    "import panel as pn\n",
    "from panel.pane import LaTeX\n",
    "hv.extension('bokeh')\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import requests\n",
    "import boto3\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_endpoint_url = 'https://object-rook-ceph.apps.math.cnrs.fr/'\n",
    "s3_access_key_id = '9F7EB8YBUWXDV7A4IZYW' # le contenu de secrets/dossal\n",
    "s3_secret_access_key = 'skV01Eei5M3xVOxROIDr3qymYhWtkrxPpMyj8nwb' # le contenu de secrets/dossal\n",
    "s3_bucket = 'signal-image'\n",
    "s3 = boto3.client('s3',\n",
    "                  '',\n",
    "                  endpoint_url = s3_endpoint_url,\n",
    "                  aws_access_key_id = s3_access_key_id,\n",
    "                  aws_secret_access_key = s3_secret_access_key)\n",
    "Data=[\"Lenna.jpg\",\"Canaletto.jpeg\",\"MinotaureBruite.jpeg\",\"Cartoon.jpg\"]\n",
    "if not os.path.isfile('Lenna.jpg'):\n",
    "    for filenames in Data:  \n",
    "        s3.download_file(s3_bucket,filenames,filenames)\n",
    "def chargeData(name):\n",
    "    if name=='Lenna':\n",
    "        res=np.array(Image.open(\"Lenna.jpg\")).astype(float)\n",
    "    if name=='Canaletto':\n",
    "        res=np.array(Image.open(\"Canaletto.jpeg\")).astype(float)\n",
    "    if name=='Minotaure':\n",
    "        res=np.array(Image.open(\"MinotaureBruite.jpeg\")).astype(float)  \n",
    "    if name=='Cartoon':\n",
    "        res=np.array(Image.open(\"Cartoon.jpg\")).astype(float) \n",
    "    return res\n",
    "options1=dict(width=400,height=400,xaxis=None,yaxis=None,toolbar=None)\n",
    "options2=dict(width=700,height=400,xaxis=None,yaxis=None,toolbar=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximation linéaire et non linéaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im2=chargeData('Lenna')\n",
    "im=chargeData('Canaletto')\n",
    "imagesRef= {\"Lenna\" : im2,\"Canaletto\" : im}\n",
    "options = dict(cmap='gray',xaxis=None,yaxis=None,width=400,height=400,toolbar=None)\n",
    "pn.Row(hv.Raster(imagesRef[\"Lenna\"]).opts(**options),hv.Raster(imagesRef[\"Canaletto\"]).opts(**options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=400\n",
    "WT= pywt.wavedecn(im, 'haar', mode='per', level=2)\n",
    "arr, coeff_slices = pywt.coeffs_to_array(WT)\n",
    "hv.Image(arr).opts(cmap='gray',width=size,height=size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire une fonction qui réalise une approxiamtion non linéaire en seuillant les coefficients d'ondelettes.\n",
    "On pourra utiliser les fonctions suivante : pywt.coeffs_to_array et pywt.array_to_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ApproxOnd2D(S,qmf,L,threshold):\n",
    "    \n",
    "    # On décompose l'image S avec la base d'ondelettes qmf\n",
    "    WTB= pywt.wavedecn(S, qmf, mode='per', level=L)\n",
    "    arr, coeff_slices = pywt.coeffs_to_array(WTB)\n",
    "    \n",
    "    # On applique le seuillage doux : on met à 0 les coefficients inférieur au seuil\n",
    "    WTS=arr*(np.abs(arr)>threshold)\n",
    "    \n",
    "    # On reconstruit l'image avec la base d'ondelettes et les nouveaux coefficients\n",
    "    ncoeffs = pywt.array_to_coeffs(WTS, coeff_slices)\n",
    "    Srec=pywt.waverecn(ncoeffs,qmf,mode='per')\n",
    "    \n",
    "    return Srec,ncoeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire une focntion PSNR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSNR(I,Iref):\n",
    "    \n",
    "    # On calcule l'erreur quadratique moyenne\n",
    "    mse = np.mean( (Iref - I) ** 2 )\n",
    "    \n",
    "    # Si l'erreur entre les deux images est nulle. cela signifie que l'image est parfaitement reconstruite donc le PSNR = 100\n",
    "    if mse == 0:\n",
    "        return 100\n",
    "    \n",
    "    Val_MAX = np.max(Iref)\n",
    "    return 20 * np.log10(Val_MAX / np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire une fonction qui réalise une approximation non linéaire en conservant un nombre N de coefficients d'ondelettes et la tester. On pourra utiliser les fonctions pywt.ravel_coeffs et unravel_coeffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ApproxOnd2nonlin(I,qmf,L,N):\n",
    "    \n",
    "    rows, cols = I.shape\n",
    "    N1 = rows*cols\n",
    "    \n",
    "    # On cherche le niveau maximum possible de décomposition dans cette base\n",
    "    Lmax = pywt.dwtn_max_level((rows,cols), pywt.Wavelet(qmf))\n",
    "    L1 = int(min(L, Lmax))\n",
    "\n",
    "    WT = pywt.wavedec2(I, qmf, mode='per', level=L1)\n",
    "    arr, coeff_slices, shapes = pywt.ravel_coeffs(WT)\n",
    "\n",
    "    # On garde les N plus grand coefficients \n",
    "    # C'est similaire à précédemment sauf que cette fois-ci on ne choisit pas un seuil mais un nombre de coefficients à garder\n",
    "    # D'où le fait qu'on prenn les plus importants.\n",
    "    Ind = np.argsort(np.abs(arr))\n",
    "    WTS = np.zeros(N1)\n",
    "    WTS[Ind[int(N1-N):int(N1)]] = arr[Ind[int(N1-N):int(N1)]]\n",
    "\n",
    "    coeffs_from_arr = pywt.unravel_coeffs(WTS, coeff_slices,shapes)\n",
    "    Irec = pywt.waverecn(coeffs_from_arr, qmf, mode='per')\n",
    "    \n",
    "    p = PSNR(I, Irec)\n",
    "    return Irec, p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer un Dashboard qui permet d'explorer la fonction précédente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelist = ['haar','db2','db3','db4','coif1','coif2','coif3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Approx2D(param.Parameterized):\n",
    "    image = param.ObjectSelector(default=\"Canaletto\",objects=imagesRef.keys())\n",
    "    wave = param.ObjectSelector(default=\"haar\",objects=wavelist)\n",
    "    L = param.Integer(5,bounds=(0,10))\n",
    "    N = param.Integer(2000,bounds=(1,10000))\n",
    "  #  @param.depends('wave', 'N', 'L')\n",
    "    def view(self):\n",
    "        Irec, p = ApproxOnd2nonlin(imagesRef[self.image],self.wave,self.L,self.N)\n",
    "        return pn.Column(hv.Image(Irec).opts(cmap='gray',width=400,height=400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approx2D = Approx2D()\n",
    "#pn.Row(approx2D.param,approx2D.view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer un plan d'experiences qui permet d'explorer la fonction ApproxOnd2nonlin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "wavelist = ['haar','db2','db3','db4','coif1','coif2','coif3']\n",
    "experiences = {'Image':imagesRef,'N':np.linspace(1000,50000,30),'wave':wavelist,'L':np.linspace(1,10,5)}\n",
    "dfexp = pd.DataFrame(list(itertools.product(*experiences.values())),columns=experiences.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer la fonction qui à une ligne de la base de donnée précédente calcule le PSNR associé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row2PSNR(row):\n",
    "    I,p=ApproxOnd2nonlin(imagesRef[row.Image], row['wave'],  row['L'], row['N'])\n",
    "    return {'PSNR':p}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appliquer la fonction sur la base de donnée et ajouter la colonne PSNR à la base de données dfexp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result2 = dfexp.apply(row2PSNR, axis=1)\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfexp['PSNR'] = pd.DataFrame.from_records(result2)['PSNR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfexp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utiliser hvplot pour visualiser la base de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hvplot.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.models import HoverTool\n",
    "h = HoverTool()\n",
    "dfexp.hvplot('N','PSNR',by='wave',kind='scatter',groupby=['Image','L'])\\\n",
    ".opts(width=600,tools = [h]).redim.range(PSNR=(20,70),translation=(-0.5,10.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut remarquer que pour les images, plus L augmente, plus le PSNR en fonction de N est linéaire. De plus, on observe que le PSNR avec la base Haar est le plus faible, et celui avec la base coif3 est meilleur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Débruitage d'images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire une fonction qui effectue un seuillage dur en ondelettes et la tester. On pourra utiliser la fonction pywt.ravel_coeffs et on pensera à cliper le résultat entre 0 et 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SeuillageDurOndelettes(I,qmf,L,Seuil):\n",
    "    \n",
    "        WTB= pywt.wavedecn(I, qmf, mode='per', level=L)\n",
    "        coeff_arr, coeff_slices, coeff_shapes = pywt.ravel_coeffs(WTB)\n",
    "        WTS=coeff_arr*(np.abs(coeff_arr)>Seuil)\n",
    "        coeffs_from_arr = pywt.unravel_coeffs(WTS, coeff_slices,coeff_shapes)\n",
    "        Irec=pywt.waverecn(coeffs_from_arr,qmf,mode='per')\n",
    "        \n",
    "        # On clip l'image pour avoir des valeurs d'intensité de gris entre 0 et 255.\n",
    "        Irec=np.clip(Irec,0,255)\n",
    "        \n",
    "        return Irec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construire un dashboard qui permet d'explorer la fonction SeuillageDurOndelettes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveSeuillage(param.Parameterized):\n",
    "    image = param.ObjectSelector(default=\"Canaletto\",objects=imagesRef.keys())\n",
    "    wave = param.ObjectSelector(default=\"haar\",objects=wavelist)\n",
    "    L = param.Integer(7,bounds=(0,7))\n",
    "    Seuil = param.Number(10,bounds=(1,1000))\n",
    "    def view(self):\n",
    "        Irec = SeuillageDurOndelettes(imagesRef[self.image],self.wave,self.L,self.Seuil)\n",
    "        return pn.Column(hv.Image(Irec).opts(cmap='gray',width=400,height=400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveseuil = WaveSeuillage()\n",
    "pn.Row(waveseuil.param,waveseuil.view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On observe que plus le seuil augmente, plus l'image noircie. En effet dans notre code, on ne garde que les coefficients qui sont supérieurs au seuil. Si le pixel apparait noir c'est que le coefficient correspondant a été mis à nul.\n",
    "On remarque également que plus L est grand, plus on perd de l'information. C'est du au fait que l'on décompose notre image en petits carrés de taille L*L."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1,n2=np.shape(im)\n",
    "B=np.random.randn(n1,n2)\n",
    "sigma=10\n",
    "ib=im+sigma*B\n",
    "ib=np.clip(ib,0,255)\n",
    "hv.Image(ib).opts(cmap='gray',width=400,height=400)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire un dashboard qui permet de visualiser rapidement l'effet d'un débruitage en ondelettes et qui renvoie les images originales, bruitées et débruitées ainsi que les PSNR associés aux images bruitées et débruitées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Debruit(I,qmf,seednoise,sigma,Seuil):\n",
    "    \n",
    "    N1,N2 = np.shape(I)\n",
    "    np.random.seed(seed=seednoise)\n",
    "    bruit=np.random.normal(0,1,(N1,N2))\n",
    "    \n",
    "    Lmax=pywt.dwtn_max_level((N1,N2), pywt.Wavelet(qmf))\n",
    "    \n",
    "    # On bruite notre image\n",
    "    IB=I+sigma*bruit\n",
    "    \n",
    "    IB=np.clip(IB,0,255)\n",
    "    \n",
    "    Seuil = Seuil*sigma \n",
    "    Irec=SeuillageDurOndelettes(IB,qmf,Lmax,Seuil)\n",
    "    \n",
    "    psnr1=PSNR(I,IB)\n",
    "    psnr2=PSNR(I,Irec)\n",
    "    \n",
    "    return Irec,IB,psnr1,psnr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Irec, IB, p1, p2=Debruit(im,'db2',6,30,6)\n",
    "# pn.Row(hv.Image(im).opts(cmap='gray',width=400,height=400),hv.Image(IB).opts(cmap='gray',width=400,height=400),hv.Image(Irec).opts(cmap='gray',width=400,height=400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def DebruitPSNR(I,qmf,N,sigma,Seuil):\n",
    "    seednoise=np.arange(N)\n",
    "    N1,N2  = I.size\n",
    "    Lmax=pywt.dwtn_max_level((N1,N2), pywt.Wavelet(qmf))\n",
    "    Seuil = Seuil*sigma\n",
    "    psnr1=np.zeros(N)\n",
    "    for k in seednoise:\n",
    "        np.random.seed(seed=seednoise)\n",
    "        bruit=np.random.normal(0,1,(N1,N2))\n",
    "        IB=I+sigma*bruit\n",
    "        Irec=SeuillageDurOndelettes(IB,qmf,Lmax,Seuil)\n",
    "        psnr1[k]=PSNR(I,Irec)\n",
    "    return np.mean(psnr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDebruit(param.Parameterized):\n",
    "    image = param.ObjectSelector(default=\"Lenna\",objects=imagesRef.keys())\n",
    "    wave = param.ObjectSelector(default=\"haar\",objects=wavelist)\n",
    "    L = param.Integer(5,bounds=(0,7))\n",
    "    Seuil = param.Number(3,bounds=(1,6))\n",
    "    Sigma = param.Number(10,bounds=(1,30))\n",
    "    seednoise = param.Integer(1,bounds=(0,50))\n",
    "    def view(self):\n",
    "        I=imagesRef[self.image]\n",
    "        Irec,IB,p1,p2=Debruit(I,self.wave,self.seednoise,self.Sigma,self.Seuil)\n",
    "        im=hv.Image(I).opts(cmap='gray',width=400,height=400)\n",
    "        imB=hv.Image(IB).opts(title = f'Image bruitée, PSNR = {p1}',cmap='gray',width=400,height=400)\n",
    "        imRec=hv.Image(Irec).opts(title = f'Image reconstruite, PSNR = {p2}',cmap='gray',width=400,height=400)\n",
    "        return pn.Row( pn.Column(im), pn.Column(imB),pn.Column(imRec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "imdebruit = ImageDebruit()\n",
    "#pn.Row(imdebruit.param,imdebruit.view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Débruitage d'images et translations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire une fonction qui réalise un débruitage avec une moyenne sur des NbT fois NbT translations et la tester. Vérifier le gain en PNSR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DebruitTranslation(IB,wave,seednoise,seuil,NbT):\n",
    "    N1,N2 = I.shape\n",
    "    np.random.seed(seed=seednoise)\n",
    "    bruit=np.random.normal(0,1,(N1,N2))\n",
    "    Lmax=pywt.dwtn_max_level((N1,N2),pywt.Wavelet(wave))\n",
    "    ISum=0*IB\n",
    "    P=np.zeros(NbT)\n",
    "    for dx in np.arange(0,NbT):\n",
    "        for dy in np.arange(0,NbT):\n",
    "            IBtemp=np.roll(np.roll(IB,dx,axis=0),dy,axis=1)\n",
    "            Irectemp=SeuillageDurOndelettes(IBtemp,wave,Lmax,seuil)\n",
    "            Irectemp2=np.roll(np.roll(IB,-dx,axis=0),-dy,axis=1)\n",
    "            ISum+=Irectemp2\n",
    "    Irec=ISum/(NbT*NbT)\n",
    "    return Irec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = im\n",
    "wave = 'haar'\n",
    "seednoise = 10\n",
    "sigma = 10\n",
    "Seuil = 3\n",
    "NbT = 5\n",
    "\n",
    "Irec, IB, p1, p2 = Debruit(I,wave,seednoise,sigma,Seuil)\n",
    "seuil = sigma*Seuil\n",
    "Irec_trans = DebruitTranslation(IB,wave,seednoise,seuil,NbT)\n",
    "p3 = PSNR(I,Irec_trans)\n",
    "\n",
    "im_originale = hv.Image(I).opts(title = \"Image originale\",cmap='gray',width=400,height=400)\n",
    "im_bruitee = hv.Image(IB).opts(title = f'image bruitée, PSNR = {p1}',cmap='gray',width=400,height=400)\n",
    "im_rec = hv.Image(Irec_trans).opts(title = f'image reconstituée, PSNR = {p3}',cmap='gray',width=400,height=400)\n",
    "\n",
    "#pn.Row(im_originale,im_bruitee,im_rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer un dasboard pour explorer la fonction précédente. La sortie doit aussi être composée de 3 images et 2 PSNR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Debruit_translat(param.Parameterized):\n",
    "    image = param.ObjectSelector(default=\"Canaletto\",objects=imagesRef.keys())\n",
    "    wave = param.ObjectSelector(default=\"haar\",objects=wavelist)\n",
    "    NbT = param.Integer(2,bounds=(1,8))\n",
    "    Seuil = param.Number(3,bounds=(1,6))\n",
    "    Sigma = param.Number(10,bounds=(1,30))\n",
    "    seednoise = param.Integer(1,bounds=(0,50))\n",
    "    def view(self):\n",
    "        I=imagesRef[self.image]\n",
    "        Irec,IB,p1,p2=Debruit(I,self.wave,self.seednoise,self.Sigma,self.Seuil)\n",
    "        seuil = self.Sigma*self.Seuil\n",
    "        Irec_trans = DebruitTranslation(IB,self.wave,self.seednoise,seuil,self.NbT)\n",
    "        p3 = PSNR(I,Irec_trans)\n",
    "        im=hv.Image(I).opts(title = \"Image Originale\",cmap='gray',width=400,height=400)\n",
    "        imB=hv.Image(IB).opts(title = f'Image bruitée, PSNR = {p1}',cmap='gray',width=400,height=400)\n",
    "        imRec=hv.Image(Irec).opts(title = f'Image reconstruite, PSNR = {p3}',cmap='gray',width=400,height=400)\n",
    "        return pn.Row( pn.Column(im), pn.Column(imB),pn.Column(imRec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdebruit_trans = Debruit_translat()\n",
    "#pn.Row(imdebruit_trans.param,imdebruit_trans.view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Débruitage d'une image couleur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour effectuer le débruitage d'une image générale, c'est à dire d'une image couleur dont le format n'est pas carré et dont les dimensions ne sont pas des puissnaces de 2 on procède comme suit :\n",
    "\n",
    "1) On effectue un débruitage séparé sur chacun des canaux.\n",
    "\n",
    "2) Le format carré n'est pas un vraiu problème, il faut juste que les dimensions soit des multiples de puissances de \n",
    "2. C'est la puissance de 2 qui définira l'échalle maximale de la décomposition en ondelettes. Il est donc préférable que les dimensions de l'images soient un petit multiple d'une puissance de 2.\n",
    "\n",
    "3) On étend l'image par symétrie ou périodicité pour qu'elle ait les dimensions souhaitées. A la fin du processus de débruitage on tronque le résultat obtenu à la dimension de l'image originale.\n",
    "\n",
    "4) Si le niveau de bruit n'est pas connu, il faut l'estimer en utilisant les coefficients d'ondelettes de la plus petite échelle (voir le notebook sur le débruitage de signaux).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposer une fonction qui effectue le débruitage d'une image couleur de dimensions quelconques. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction peut prendre en entrée un tableau numpy ou une image dans une format d'images classique.\n",
    "Vous pouvez tester votre programme en bruitant vous même une ou plusieurs images de référence et évaluer le gain en terme de PSNR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Debruit_CI(I, qmf, seednoise, sigma=None, Seuil=None):\n",
    "    # Séparation des canaux\n",
    "    N1, N2, N3 = I.shape\n",
    "    denoised_image = np.zeros((N1,N2,N3))\n",
    "    \n",
    "    for channel in range(N3):\n",
    "        Irec,IB,psnr1,psnr2 = Debruit(I[:,:,channel],qmf,seednoise,sigma,Seuil)\n",
    "        denoised_image[:,:,channel]=Irec\n",
    "    psnr = PSNR(I,denoised_image)\n",
    "    return denoised_image, psnr    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pour aller plus loin (à titre informatif et optionnel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut améliorer les méthodes par seuillage dans une base d'ondelettes en effectuant un seuillage par blocs. C'est à dire, ne pas décider de conserver ou pas un coefficients en fonction de sa seule amplitude mais plutôt en fonction de l'énergie d'un voisinage de coefficients. \n",
    "\n",
    "Voir : http://www.cnrs.fr/insmi/spip.php?article265\n",
    "\n",
    "En effet, il est rare qu'un coefficient soit significatif seul au milieu de coefficients nuls. \n",
    "\n",
    "La mméthode de sueillage par blocs consiste à choisir une taille de voisinage (par exemple 4*4 coeffients en dimension 2) pour une échelle et une direction donnée et de conserver l'intégralité des coefficients si l'énergie (la somme des carrés des coefficients) est supérieure à un seuil et de les mettre tous à 0 si ce n'est pas le cas. \n",
    "\n",
    "Dans ce cas aussi, les translations permettent d'améliorer le rendu visuel en limitant les effets de blocs.\n",
    "\n",
    "On peut aussi constuire des blocs \"3D\" en considérant des blocs qui comprennent les coefficients des 3 créneaux de couleurs. L'idée est de corréler le débruitage un peu à travers l'espace et l'espace des couleurs.\n",
    "\n",
    "Il est possible d'effectuer un débruitage en changeant d'espace colorimétrique en passant du RGB au YUV par exemple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Débruiter un minotaure ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A l'aide de tout ce qui a été fait précédemment, proposer une version débruitée de l'image couleur contenue dans le tableau Mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mi=chargeData('Minotaure')\n",
    "Minotaure=np.clip(Mi,0,255)\n",
    "#hv.RGB(Minotaure.astype('uint8')).opts(xlabel=None,ylabel=None,width=400,height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Mi.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rédiger également une fonction prenant en entrée un nom de fichier \n",
    "permettant de calculer le PSNR de votre proposition d'image débruitée avec l'image en question.\n",
    "On calcule le PSNR entre deux images couleurs en calculant la somme des erreurs quadratiques sur les 3 canaux.\n",
    "\n",
    "Attention, l'image a 3 canaux de couleur, n'est pas carrée et les dimensions ne sont pas des puissances de 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wave = 'haar'\n",
    "seednoise = 10\n",
    "sigma = 10\n",
    "Seuil = 3\n",
    "\n",
    "Irec_c, p2 = Debruit_CI(Minotaure,wave,seednoise,sigma,Seuil)\n",
    "min_o = hv.RGB(Minotaure.astype('uint8')).opts(xlabel=None,ylabel=None,width=400,height=500)\n",
    "min_r = hv.RGB(Irec_c.astype('uint8')).opts(xlabel=None,ylabel=None,width=400,height=500)\n",
    "\n",
    "pn.Row(min_o,min_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Debruit_color(param.Parameterized):\n",
    "    wave = param.ObjectSelector(default=\"haar\",objects=wavelist)\n",
    "    Seuil = param.Number(3,bounds=(1,6))\n",
    "    Sigma = param.Number(10,bounds=(1,30))\n",
    "    seednoise = param.Integer(1,bounds=(0,50))\n",
    "    def view(self):\n",
    "        Irec,p2=Debruit_CI(Minotaure,self.wave,self.seednoise,self.Sigma,self.Seuil)\n",
    "        seuil = self.Sigma*self.Seuil\n",
    "        im=hv.RGB(Minotaure.astype('uint8')).opts(xlabel=None,ylabel=None,width=400,height=500)\n",
    "        imRec=hv.RGB(Irec.astype('uint8')).opts(title = f'Image débruitée, PSNR = {p2}',xlabel=None,ylabel=None,width=400,height=500)\n",
    "        return pn.Row( pn.Column(im), pn.Column(imRec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdebruit_color = Debruit_color()\n",
    "pn.Row(imdebruit_color.param,imdebruit_color.view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plan d'expériences pour évaluer l'impact des translations  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer un plan d'expériences pour explorer les performances de l'invariance par translation pour le débruitage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiences_DebruitTrans = {'NbT':np.arange(1,5),'wave':wavelist,'Sigma':np.linspace(10,30,2)}\n",
    "dfexp_DebruitTrans = pd.DataFrame(list(itertools.product(*experiences_DebruitTrans.values())),columns=experiences_DebruitTrans.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfexp_DebruitTrans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire une fonction qui calcule le PSNR moyen sur n réalisations de bruit du débruitage d'une image avec NbT*NbT translations (qui utilise par exemple la fonction DebruitTranslation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Debruit_Translat_PSNRMoyen(I,wave,sigma,NbT,n):\n",
    "    P=np.zeros(n)\n",
    "    N1,N2=np.shape(I)\n",
    "    for seednoise in np.arange(0,n):\n",
    "        np.random.seed(seed=seednoise)\n",
    "        bruit=np.random.normal(0,1,(N1,N2))\n",
    "        IB=I+sigma*bruit\n",
    "        Irec=DebruitTranslation(IB,wave,seednoise,seuil,NbT)\n",
    "        P[seednoise]=PSNR(I,Irec)\n",
    "    return np.mean(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Debruit_Translat_PSNRMoyen(I, wave, sigma, NbT, n):\n",
    "    P = np.zeros(n)\n",
    "    N1, N2, _ = I.shape  # Obtenez les dimensions de l'image, y compris le nombre de canaux\n",
    "    for seednoise in range(n):\n",
    "        np.random.seed(seed=seednoise)\n",
    "        bruit = np.random.normal(0, 1, (N1, N2, 3))  # Générez un bruit pour chaque canal\n",
    "        IB = I + sigma * bruit\n",
    "        Irec = np.zeros_like(I)\n",
    "        # Débruitage séparé sur chaque canal\n",
    "        for c in range(3):\n",
    "            Irec[:, :, c] = DebruitTranslation(IB[:, :, c], wave, seednoise, seuil, NbT)\n",
    "        # Calcul du PSNR pour l'image débruitée\n",
    "        P[seednoise] = PSNR(I, Irec)\n",
    "    return np.mean(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire la fonction qui à une ligne de la base de données précédente calcule le PSNR moyen sur 4 réalisations du bruit. Puis l'appliquer à la base de données et ajouter la colonne des PSNR calculés à la base de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row2DebruitTrans(row):\n",
    "    N=4\n",
    "    seednoise = 10\n",
    "    p=Debruit_Translat_PSNRMoyen(Minotaure,row.wave,row.Sigma,row.NbT,N)\n",
    "    return {'PSNR':p}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = dfexp_DebruitTrans.apply(row2DebruitTrans,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfexp_DebruitTrans[['PSNR']] = pd.DataFrame.from_records(result.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfexp_DebruitTrans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utiliser hvplot pour visualiser les résulatst contenus dans la base de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = HoverTool()\n",
    "dfexp_DebruitTrans.hvplot('NbT','PSNR',by='wave',kind='scatter',groupby=['Sigma'])\\\n",
    ".opts(width=600,tools = [h]).redim.range(PSNR=(0,40),translation=(-0.5,10.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantification et Entropie de Shannon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ShannonEntropy(x):\n",
    "    value,counts = np.unique(x, return_counts=True)\n",
    "    Proba=counts/len(x)\n",
    "    Ent=-np.sum(np.log2(Proba)*Proba)\n",
    "    return Ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array([13,13,2,7,13,7,1,13])\n",
    "print(ShannonEntropy(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.array([-2,-3,1,0,1,0,-2,-3])\n",
    "print(ShannonEntropy(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire une fonction qui effectue la quantification de la transformée en ondelettes avec un pas \"Pas\". On pourra à nouveau utiliser la commande pywt.ravel_coeffs. La fonction doit renvoyer l'image calculée par quantification, le PSNR associé ainsi que le nombre d'octets estimé par la valeur de l'entropie a priori nécessaire pour coder une telle image. On considérera qu'on code séparément les coefficients d'échelle et les coefficients d'ondelettes. Tester la fonction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QuantificationOndelettes(I,qmf,Pas):\n",
    "    coeffs = pywt.wavedecn(I, qmf)\n",
    "    coeff_arr, coeff_slices, coeff_shapes = pywt.ravel_coeffs(coeffs)\n",
    "    quant_scale = np.round(coeff_arr[0] / Pas) * Pas\n",
    "    quant_wavelets = np.round(coeff_arr[1:] / Pas) * Pas\n",
    "    quant_coeffs = pywt.unravel_coeffs((quant_scale,) + tuple(quant_wavelets), coeff_slices, coeff_shapes)\n",
    "    image_quant = pywt.waverecn(quant_coeffs,qmf)\n",
    "    psnr = PSNR(I, image_quant)\n",
    "    entropy_scale = sum(abs(np.diff(np.sort(np.unique(quant_scale)))))\n",
    "    entropy_wavelets = sum(abs(np.diff(np.sort(np.unique(quant_wavelets)))))\n",
    "    bytes_needed = (entropy_scale + entropy_wavelets) * np.prod(I.shape) / 8\n",
    "    return image_quant, psnr, bytes_needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer le dashboard asscoié à la focntion précédente. \n",
    "Le dashboard doit renvoyer l'image quantifiée, le PSNR de l'image ainsi que le facteur de compression théorique associé. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveQuant(param.Parameterized):\n",
    "    image = param.ObjectSelector(default=\"Canaletto\",objects=imagesRef.keys())\n",
    "    wave = param.ObjectSelector(default=\"haar\",objects=wavelist)\n",
    "    QS = param.Number(30,bounds=(10,300))\n",
    "    def view(self) :\n",
    "        Iq,psnr,B = QuantificationOndelettes(imagesRef[self.image],self.wave,self.QS)\n",
    "        im=hv.Image(imagesRef[self.image]).opts(title = f'Image originale', cmap='gray',width=400,height=400)\n",
    "        imQ=hv.Image(Iq).opts(title = f'Image reconstruite, PSNR = {psnr}, Bytes = {B}',cmap='gray',width=400,height=400)\n",
    "        return pn.Row( pn.Column(im), pn.Column(imQ))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wave_Quan = WaveQuant()\n",
    "#pn.Row(Wave_Quan.param,Wave_Quan.view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer dun plan d'expériences pour comparer les différentes ondelettes pour la quantification... et poursuivre jusqu'à obtenir un affichage de la base de données ainsi créée avec hvplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiences_quant = {'Image':imagesRef, 'QS':np.linspace(30,200,10),'wave':wavelist}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfexp_experiences_quant = pd.DataFrame(list(itertools.product(*experiences_quant.values())),columns=experiences_quant.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfexp_experiences_quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row2DistorsionRate(row):\n",
    "    I,p,B=QuantificationOndelettes(imagesRef[row.Image],row.wave,row.QS)\n",
    "    return {'PSNR':p}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = dfexp_experiences_quant.apply(row2DistorsionRate,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfexp_experiences_quant[['PSNR']] = pd.DataFrame.from_records(result.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfexp_experiences_quant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pour aller plus loin (à titre informatif et optionnel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous proposons ici d'effectuer la compression sur les 3 canau RGB. Or l'oeil humain est plus sensible à la luminance qu'aux composantes purement chromatiques. C'est pourquoi, la plupart des algorithmes de compressions sont effectué dans un espace colorimétrique YUV où Y est la luminance. On alloue alors plus d'information au canal Y et on comprime plus drastiquement les deux autres canaux. Une méthode standart consiste par exemple à sous-échantionner d'un facteur 2 les deux composantes U et V avant de les comprimer. \n",
    "\n",
    "https://fr.wikipedia.org/wiki/Sous-échantillonnage_de_la_chrominance\n",
    "\n",
    "On obtient alors des images de chrominances moins résolues et donc moins lourdes mais le rendu final reste correct car l'oeil humain est nettement plus sensible à la luminance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
